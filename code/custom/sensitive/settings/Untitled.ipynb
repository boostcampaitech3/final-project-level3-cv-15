{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d5dee98-0c80-4604-8a1a-1711e0259011",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from importlib import import_module\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import albumentations as A\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import dataloader\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c43cd5b2-a4fd-449e-a558-b770aabcfbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = A.Compose([\n",
    "        # A.CLAHE(always_apply=False, p=1 , clip_limit=(8, 8), tile_grid_size=(8, 8)),\n",
    "        # A.GridDistortion(always_apply=False, p=0.3, num_steps=5, distort_limit=(-0.3, 0.3), interpolation=0, border_mode=0, value=(0, 0, 0), mask_value=None),\n",
    "        # A.HorizontalFlip(always_apply=False, p=0.5),\n",
    "        # A.CoarseDropout(always_apply=False, p=1.0, max_holes=14, max_height=8, max_width=8, min_holes=14, min_height=8, min_width=8),\n",
    "                            ToTensorV2()\n",
    "                            ])\n",
    "    \n",
    "val_transform = A.Compose([\n",
    "        # A.CLAHE(always_apply=False, p=1 , clip_limit=(8, 8), tile_grid_size=(8, 8)),\n",
    "                            ToTensorV2()\n",
    "                            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af412d3d-4069-4201-8dcc-f13135ab8e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, valid_loader = dataloader.getDataloader(train_transform, val_transform, 16, 4,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70ed64d0-bad9-4373-bed7-f411bc4b0f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "re = []\n",
    "for i in train_loader:\n",
    "    i = i[1].tolist()\n",
    "    re.extend(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "787af58d-460e-4624-a795-152f58702003",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 645, 4: 718, 1: 693, 3: 653, 2: 681})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ef972d-fe3a-4efc-9019-d87ac6cd874e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmseg",
   "language": "python",
   "name": "mmseg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
